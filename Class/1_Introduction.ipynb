{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w24O8k6luzVo"
   },
   "source": [
    "# **<font color='darkorange'>Introduction to Machine Learning</font>**\n",
    "\n",
    "**Machine Learning** is a subset of Artificial Intelligence (AI) that enables computers to **learn from data** and make decisions or predictions **without being explicitly programmed**. Instead of relying on hard-coded rules, machine learning systems improve their performance as they process more data over time.\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?id=1jEUBnfczk1eFom8nS1duQC8cVFEkHvDm\" alt=\"Types\" width=\"700\"/>\n",
    "\n",
    "---\n",
    "## **<font color='blue'>What is Machine Learning?</font>**\n",
    "\n",
    "Machine Learning focuses on developing algorithms that can:  \n",
    "- **Learn** from historical data.  \n",
    "- **Identify patterns** and relationships within the data.  \n",
    "- **Predict outcomes** or take actions on new, unseen data.\n",
    "\n",
    "### **Key Characteristics**:\n",
    "1. **Data-Driven**: ML systems rely heavily on data to make decisions.  \n",
    "2. **Iterative**: The more data an ML model processes, the better it gets.  \n",
    "3. **Adaptive**: ML models can adapt and adjust as the environment or data changes.\n",
    "\n",
    "---\n",
    "- [Machine Learning is the] field of study that gives computers the ability to learn\n",
    "without being explicitly programmed.\n",
    "— Arthur Samuel, 1959\n",
    "- A computer program is said to learn from experience E with respect to some task T\n",
    "and some performance measure P, if its performance on T, as measured by P,\n",
    "improves with experience E.\n",
    "— Tom Mitchell, 1997\n",
    "\n",
    "<div style=\"display: flex; justify-content: space-around;\">\n",
    "    <img src=\"https://drive.google.com/uc?id=1-Mdprb3HNf_cbjjHhde4tYCTrWYKhntx\" width=\"500\"/>\n",
    "    <img src=\"https://drive.google.com/uc?id=1p4gasbgwONGCXcYbOpa59ur2nRuFjw15\" width=\"500\"/>\n",
    "</div>\n",
    "---\n",
    "\n",
    "## **<font color='green'>Why is Machine Learning Important?</font>**\n",
    "\n",
    "Machine Learning is at the core of many modern technologies and applications, including:  \n",
    "- Personalized recommendations (e.g., Netflix, Amazon).  \n",
    "- Predictive maintenance in industries.  \n",
    "- Spam detection in emails.  \n",
    "- Medical diagnosis and image analysis.  \n",
    "- Autonomous vehicles and robotics.  \n",
    "\n",
    "By analyzing vast amounts of data, ML helps businesses and organizations:  \n",
    "- Automate decision-making.  \n",
    "- Reduce costs and improve efficiency.  \n",
    "- Discover insights that humans may overlook.  \n",
    "\n",
    "---\n",
    "\n",
    "## **<font color='purple'>Types of Machine Learning</font>**\n",
    "\n",
    "Machine Learning problems are broadly categorized into three types based on the nature of data and tasks:\n",
    "\n",
    "1. **<font color='blue'>Supervised Learning</font>**  \n",
    "   - Learning from **labeled data** (input-output pairs).  \n",
    "   - Example: Predicting house prices based on size, bedrooms, and location.\n",
    "\n",
    "2. **<font color='green'>Unsupervised Learning</font>**  \n",
    "   - Learning from **unlabeled data** to identify patterns.  \n",
    "   - Example: Grouping customers into segments based on spending habits.\n",
    "\n",
    "3. **<font color='purple'>Reinforcement Learning</font>**  \n",
    "   - Learning through **trial and error** to maximize rewards in an environment.  \n",
    "   - Example: Teaching a robot to navigate a room by rewarding correct moves.\n",
    "\n",
    "---\n",
    "\n",
    "## **<font color='darkorange'>Conclusion</font>**\n",
    "\n",
    "Machine Learning has transformed the way systems interact with data, enabling innovations in **business, healthcare, finance, and technology**. By understanding its core concepts and categories, we can develop powerful solutions to solve real-world problems.\n",
    "\n",
    "---\n",
    "\n",
    "Next, let’s explore the **Types of Machine Learning Problems** in detail:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zOJ2zRYseSJG"
   },
   "source": [
    "# **<font color='darkorange'>Types of Machine Learning Problems</font>**\n",
    "\n",
    "Machine Learning problems are broadly categorized into three types based on the nature of data and tasks:\n",
    "\n",
    "1. **<font color='blue'>Supervised Learning</font>**  \n",
    "2. **<font color='green'>Unsupervised Learning</font>**  \n",
    "3. **<font color='purple'>Reinforcement Learning</font>**\n",
    "\n",
    "Each type of problem involves different goals, algorithms, and use cases.\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?id=11fWx1qW0U1UqIoBva5FF6DMooiu0kRLP\" alt=\"Types\" width=\"700\"/>/>\n",
    "\n",
    "## **<font color='blue'>1. Supervised Learning</font>**\n",
    "\n",
    "**Definition**:  \n",
    "In supervised learning, the model learns a mapping between **input features** and their corresponding **target labels**. It is called \"supervised\" because the learning process is guided by labeled data.\n",
    "\n",
    "### **Goal**:  \n",
    "- Train a model to make predictions on unseen data based on labeled training data.\n",
    "\n",
    "### **Key Concepts**:  \n",
    "- **Input Features (X)**: The independent variables.  \n",
    "- **Target Labels (Y)**: The dependent variables (known outcomes).  \n",
    "- **Training Data**: Labeled data used to train the model.  \n",
    "- **Testing Data**: Data used to evaluate the model's performance.\n",
    "\n",
    "\n",
    "### **Types**:\n",
    "1. **<font color='darkcyan'>Classification</font>**: Predicts a **categorical label**.  \n",
    "   - Example: Predict whether an email is \"Spam\" or \"Not Spam\" (binary classification).  \n",
    "   - Example: Classify handwritten digits into classes (0–9).\n",
    "\n",
    "2. **<font color='darkcyan'>Regression</font>**: Predicts a **continuous value**.  \n",
    "   - Example: Predict the price of a house based on its size and location.  \n",
    "   - Example: Forecast the temperature for the next day.\n",
    "\n",
    "\n",
    "## <font color='blue'>**Supervised Learning Example Data**</font>\n",
    "\n",
    "In supervised learning, the data has **input features** (\\(X\\)) and corresponding **labels** (\\(Y\\)).\n",
    "\n",
    "### <font color='green'>**Classification Problem**</font>\n",
    "Predict whether a customer will purchase a product (<font color='red'>**Yes/No**</font>) based on their age and income.\n",
    "\n",
    "| **Customer ID** | **Age (Years)** | **Income (USD)** | **Purchased (Y/N)** |\n",
    "|-----------------|-----------------|-----------------|---------------------|\n",
    "| 1               | 25              | 50,000          | <font color='green'>Yes</font>                 |\n",
    "| 2               | 32              | 60,000          | <font color='red'>No</font>                  |\n",
    "| 3               | 47              | 80,000          | <font color='green'>Yes</font>                 |\n",
    "| 4               | 52              | 45,000          | <font color='red'>No</font>                  |\n",
    "| 5               | 29              | 70,000          | <font color='green'>Yes</font>                 |\n",
    "\n",
    "---\n",
    "\n",
    "### <font color='green'>**Regression Problem**</font>\n",
    "Predict the **house price** based on size (sq ft), number of bedrooms, and age of the house.\n",
    "\n",
    "| **House ID** | **Size (sq ft)** | **Bedrooms** | **Age (Years)** | **Price (USD)** |\n",
    "|--------------|------------------|--------------|-----------------|-----------------|\n",
    "| 1            | 1500             | 3            | 10              | <font color='blue'>300,000</font>         |\n",
    "| 2            | 2000             | 4            | 5               | <font color='blue'>450,000</font>         |\n",
    "| 3            | 1800             | 3            | 8               | <font color='blue'>350,000</font>         |\n",
    "| 4            | 2500             | 5            | 2               | <font color='blue'>600,000</font>         |\n",
    "| 5            | 1700             | 2            | 15              | <font color='blue'>280,000</font>         |\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?id=1s6Nx_-u82ADxRj3dL5LgPbLRhk5lIuyj\" alt=\"Types\" width=\"700\"/>\n",
    "---\n",
    "\n",
    "\n",
    "### **Example Algorithms**:\n",
    "- Linear Regression  \n",
    "- Logistic Regression\n",
    "- k-Nearest Neighbors\n",
    "- Decision Trees  \n",
    "- Random Forest  \n",
    "- Support Vector Machines (SVM)  \n",
    "- Neural Networks  \n",
    "\n",
    "---\n",
    "\n",
    "## **<font color='green'>2. Unsupervised Learning</font>**\n",
    "\n",
    "**Definition**:  \n",
    "In unsupervised learning, the model learns patterns and structures from **unlabeled data** without any predefined labels or outcomes.\n",
    "\n",
    "### **Goal**:  \n",
    "- Discover hidden structures or patterns in data.\n",
    "\n",
    "### **Key Concepts**  \n",
    "- **Input Features (X)**: Independent variables with no target labels.  \n",
    "- **Clusters**: Groups of similar data points.  \n",
    "- **Dimensionality Reduction**: Simplifying data by reducing features.\n",
    "\n",
    "\n",
    "### **Types**:\n",
    "1. **<font color='teal'>Clustering</font>**: Group data points into similar clusters.  \n",
    "   - Example: Segment customers into different groups based on their purchasing behavior.  \n",
    "   - Example: Identify communities in a social network.\n",
    "\n",
    "2. **<font color='teal'>Dimensionality Reduction</font>**: Reduce the number of features in the data while retaining important information.  \n",
    "   - Example: Compress image data for faster processing.  \n",
    "   - Example: Visualize high-dimensional data in 2D/3D.\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "## <font color='purple'>**Unsupervised Learning Example Data**</font>\n",
    "\n",
    "In unsupervised learning, the data contains **input features only** (\\(X\\)). There are no target labels.\n",
    "\n",
    "### <font color='green'>**Clustering Problem**</font>\n",
    "Group customers based on their **age** and **spending score**.\n",
    "\n",
    "| **Customer ID** | **Age (Years)** | **Spending Score** |\n",
    "|-----------------|-----------------|--------------------|\n",
    "| 1               | 22              | <font color='blue'>85</font>                 |\n",
    "| 2               | 40              | <font color='red'>15</font>                 |\n",
    "| 3               | 35              | <font color='blue'>60</font>                 |\n",
    "| 4               | 28              | <font color='green'>77</font>                 |\n",
    "| 5               | 55              | <font color='red'>20</font>                 |\n",
    "| 6               | 19              | <font color='blue'>90</font>                 |\n",
    "| 7               | 48              | <font color='red'>25</font>                 |\n",
    "\n",
    "**Goal**: Discover groups of customers with similar purchasing behaviors.\n",
    "\n",
    "---\n",
    "\n",
    "### <font color='green'>**Dimensionality Reduction Problem**</font>\n",
    "Reduce the number of features in a dataset (e.g., a dataset with multiple measurements on flowers).\n",
    "\n",
    "| **Sample ID** | **Petal Length (cm)** | **Petal Width (cm)** | **Sepal Length (cm)** | **Sepal Width (cm)** |\n",
    "|---------------|-----------------------|----------------------|-----------------------|----------------------|\n",
    "| 1             | <font color='blue'>1.4</font>                   | <font color='green'>0.2</font>                  | 4.7                   | 3.2                  |\n",
    "| 2             | <font color='blue'>1.5</font>                   | <font color='green'>0.4</font>                  | 5.1                   | 3.5                  |\n",
    "| 3             | <font color='blue'>4.5</font>                   | <font color='red'>1.5</font>                  | 6.4                   | 2.9                  |\n",
    "| 4             | <font color='blue'>5.1</font>                   | <font color='red'>1.8</font>                  | 7.0                   | 3.1                  |\n",
    "| 5             | <font color='blue'>4.7</font>                   | <font color='red'>1.4</font>                  | 6.3                   | 3.3                  |\n",
    "\n",
    "**Goal**: Use techniques like **PCA** to reduce these features into fewer dimensions while retaining important patterns.\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?id=1D26H9KYCGrsTHV9VkGju0gCo5Fvg5AN5\" alt=\"Types\" width=\"700\"/>\n",
    "\n",
    "\n",
    "### **Example Algorithms**:\n",
    "- K-Means Clustering  \n",
    "- Hierarchical Clustering  \n",
    "- Principal Component Analysis (PCA)  \n",
    "- t-SNE (t-Distributed Stochastic Neighbor Embedding)  \n",
    "\n",
    "---\n",
    "\n",
    "## **<font color='purple'>3. Reinforcement Learning</font>**\n",
    "\n",
    "**Definition**:  \n",
    "Reinforcement Learning (RL) is a type of machine learning where an agent learns to make decisions by performing actions in an environment to maximize cumulative rewards.\n",
    "\n",
    "### **Goal**:  \n",
    "- Train an agent to learn an optimal strategy by interacting with the environment and receiving feedback through **rewards** or **penalties**.\n",
    "\n",
    "### **Key Concepts**:\n",
    "- **<font color='orange'>Agent</font>**: The learner or decision-maker (e.g., a robot, game player).  \n",
    "- **<font color='orange'>Environment</font>**: Where the agent interacts (e.g., a game, traffic simulation).  \n",
    "- **<font color='orange'>Actions</font>**: Possible moves the agent can take.  \n",
    "- **<font color='orange'>Rewards</font>**: Positive or negative feedback for actions taken.\n",
    "\n",
    "### **Real-World Examples**:\n",
    "- Training robots to navigate a room.  \n",
    "- Teaching computers to play games like chess or Go.  \n",
    "- Optimizing traffic light controls for smooth traffic flow.\n",
    "\n",
    "### **Example Algorithms**:\n",
    "- Q-Learning  \n",
    "- Deep Q Networks (DQN)  \n",
    "- Policy Gradient Methods  \n",
    "- SARSA (State-Action-Reward-State-Action)  \n",
    "\n",
    "---\n",
    "\n",
    "## **<font color='darkorange'>4. Summary Table</font>**\n",
    "\n",
    "| **Type**                        | **Definition**                                                                 | **Examples**                               | **Algorithms**                  |\n",
    "|---------------------------------|-------------------------------------------------------------------------------|-------------------------------------------|---------------------------------|\n",
    "| **<font color='blue'>Supervised Learning</font>**  | Learning from labeled data to make predictions.                              | Spam Detection, House Price Prediction    | Linear Regression, Decision Trees |\n",
    "| **<font color='green'>Unsupervised Learning</font>**| Finding hidden patterns in unlabeled data.                                   | Customer Segmentation, Anomaly Detection  | K-Means, PCA, Hierarchical Clustering |\n",
    "| **<font color='purple'>Reinforcement Learning</font>** | Learning by interacting with an environment to maximize rewards.            | Game Playing, Robotics, Self-Driving Cars | Q-Learning, DQN, Policy Gradient  |\n",
    "\n",
    "---\n",
    "\n",
    "## **<font color='blue'>5. Conclusion</font>**\n",
    "\n",
    "- **<font color='blue'>Supervised Learning</font>** is suitable when labeled data is available for classification or regression tasks.  \n",
    "- **<font color='green'>Unsupervised Learning</font>** is used for discovering patterns, clustering, or reducing dimensions in unlabeled data.  \n",
    "- **<font color='purple'>Reinforcement Learning</font>** focuses on decision-making and learning through interactions with an environment to maximize rewards.\n",
    "\n",
    "Each type of machine learning problem requires different algorithms and approaches, depending on the nature of the data and the objective.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8dSD_TCV0daO"
   },
   "source": [
    "# **<font color='darkorange'>Hypothesis Space and Inductive Bias</font>**\n",
    "\n",
    "Understanding the concepts of **<font color='blue'>hypothesis</font>**, **<font color='blue'>hypothesis space</font>**, and **<font color='green'>inductive bias</font>** is crucial in machine learning, as they influence how models learn from data and make predictions.\n",
    "\n",
    "---\n",
    "\n",
    "## **<font color='blue'>1. What is a Hypothesis?</font>**\n",
    "\n",
    "In **machine learning**, a **hypothesis** is a proposed explanation or model that maps input features ($X$) to outputs ($Y$). Simply put, it is a **guess** or **assumption** about the relationship between inputs and outputs based on the given data.\n",
    "\n",
    "### **Analogy**:  \n",
    "Imagine you are a detective solving a mystery. You look at the clues (input data) and propose a **hypothesis** about who committed the crime. Your job is to test this hypothesis by collecting more evidence (training data).  \n",
    "\n",
    "Similarly, in machine learning:\n",
    "- The **data** is your evidence.  \n",
    "- The **hypothesis** is the model's assumption or guess.  \n",
    "- The model's task is to verify which hypothesis best explains the data.\n",
    "\n",
    "---\n",
    "\n",
    "## **<font color='blue'>2. Hypothesis Space</font>**\n",
    "\n",
    "**Definition**:  \n",
    "The **hypothesis space** ($\\mathcal{H}$) is the set of all possible hypotheses that a learning algorithm can consider. It defines the scope of potential models the algorithm can choose from.\n",
    "\n",
    "### **Key Concepts**:\n",
    "\n",
    "- **Hypothesis ($h$)**: A specific function that maps input features ($X$) to outputs ($\\hat{Y}$).  \n",
    "- **True Function ($f$)**: The actual relationship between input and output, which is often unknown.  \n",
    "- **Model Capacity**: A larger hypothesis space can fit more complex patterns, but it may lead to overfitting.\n",
    "\n",
    "### **Example**:  \n",
    "In linear regression, the hypothesis space consists of all possible **linear functions** of the form:\n",
    "\n",
    "$$\n",
    "h(x) = w_0 + w_1 x_1 + w_2 x_2 + \\ldots + w_n x_n\n",
    "$$\n",
    "\n",
    "where $w_0, w_1, \\dots, w_n$ are parameters to be learned.\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?id=1zSPkIokR3tBfYfxh-YmcaT6o0xW3DvQK\" width=700/>\n",
    "\n",
    "---\n",
    "\n",
    "## **<font color='green'>3. Inductive Bias</font>**\n",
    "\n",
    "**Definition**:  \n",
    "**Inductive bias** refers to the assumptions a learning algorithm makes to generalize beyond the training data. Since learning algorithms cannot test every possible hypothesis, they rely on inductive bias to guide the selection process.\n",
    "\n",
    "### **Types of Inductive Bias**:\n",
    "\n",
    "1. **<font color='blue'>Preference Bias</font>**: Prefers certain hypotheses over others (e.g., simpler models).  \n",
    "2. **<font color='blue'>Restriction Bias</font>**: Limits the hypothesis space (e.g., only linear models).\n",
    "\n",
    "---\n",
    "\n",
    "## **<font color='purple'>4. Occam's Razor Principle</font>**\n",
    "\n",
    "**Definition**:  \n",
    "The **Occam's Razor Principle** states:  \n",
    "> \"Among competing hypotheses that explain the data equally well, the simplest one is preferred.\"\n",
    "\n",
    "**Why?**  \n",
    "Simpler models are easier to understand and more likely to generalize well to unseen data.\n",
    "\n",
    "### **Analogy**:  \n",
    "If two explanations solve a mystery equally well, a detective would prefer the simpler explanation because it is more likely to be correct.  \n",
    "\n",
    "**Example in Machine Learning**:  \n",
    "In regression tasks, a straight line (linear model) is preferred over a high-degree polynomial unless the data strongly suggests otherwise. A simpler model reduces the risk of overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "## **<font color='darkorange'>5. Relationship Between Hypothesis Space and Inductive Bias</font>**\n",
    "\n",
    "The **hypothesis space** and **inductive bias** are interconnected:\n",
    "\n",
    "- The **hypothesis space** defines all the possible models a learning algorithm can choose.  \n",
    "- The **inductive bias** influences which hypothesis (model) is selected from the hypothesis space.  \n",
    "\n",
    "A well-chosen inductive bias helps the model **generalize** better by narrowing down the hypothesis space to plausible solutions.\n",
    "\n",
    "---\n",
    "\n",
    "# **<font color='darkorange'>Evaluation: Training, Validation, and Test Sets</font>**\n",
    "\n",
    "Evaluating a machine learning model's performance ensures that it can generalize to unseen data. This involves splitting the dataset into **training**, **validation**, and **test** sets.\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?id=1m2PAx79t9UVOdu8yd_K-pnS1q2NnD4u1\" width=700/>\n",
    "---\n",
    "\n",
    "## **<font color='blue'>1. Training Set</font>**\n",
    "\n",
    "**Definition**:  \n",
    "The **training set** is the portion of the dataset used to train the model and learn patterns.\n",
    "\n",
    "**Key Purpose**:  \n",
    "- The model learns the relationships between input features and target labels.  \n",
    "- The model adjusts its parameters to minimize the error on this data.\n",
    "\n",
    "**Example**:  \n",
    "In a dataset of 1,000 samples, **800 samples** are used to train the model.\n",
    "\n",
    "---\n",
    "\n",
    "## **<font color='blue'>2. Validation Set</font>**\n",
    "\n",
    "**Definition**:  \n",
    "The **validation set** is a portion of the dataset used to tune the model's hyperparameters and assess performance during training.  \n",
    "\n",
    "**Key Purpose**:  \n",
    "- It helps in identifying the model's ability to generalize **before testing**.  \n",
    "- It is used for **hyperparameter tuning** (e.g., adjusting learning rate, regularization strength, etc.).  \n",
    "- Prevents overfitting by providing feedback on intermediate model performance.\n",
    "\n",
    "**Example**:  \n",
    "Out of the 1,000 samples, **100 samples** are reserved as a validation set to evaluate the model while tuning hyperparameters.\n",
    "\n",
    "---\n",
    "\n",
    "## **<font color='blue'>3. Test Set</font>**\n",
    "\n",
    "**Definition**:  \n",
    "The **test set** is a portion of the dataset reserved for the final evaluation of the model's performance on unseen data.\n",
    "\n",
    "**Key Purpose**:  \n",
    "- Provides an **unbiased evaluation** of the trained model.  \n",
    "- Helps estimate the model's **generalization performance** on new data.\n",
    "\n",
    "**Example**:  \n",
    "The remaining **100 samples** are used as the test set to evaluate the final model's accuracy or error metrics.\n",
    "\n",
    "---\n",
    "\n",
    "## **<font color='green'>4. Why Split the Data?</font>**\n",
    "\n",
    "- **Detect Overfitting**: Compare the model's performance on training, validation, and test sets to identify overfitting or underfitting.  \n",
    "- **Hyperparameter Tuning**: Use the **validation set** to optimize the model's configuration without touching the test set.  \n",
    "- **Estimate Generalization**: The test set provides a realistic measure of how the model will perform on unseen data.\n",
    "\n",
    "---\n",
    "\n",
    "## **<font color='darkorange'>5. Best Practices for Data Splitting</font>**\n",
    "\n",
    "1. **Train/Validation/Test Split**:  \n",
    "   - **70-80%** Training  \n",
    "   - **10-15%** Validation  \n",
    "   - **10-15%** Test  \n",
    "\n",
    "2. **Cross-Validation**:  \n",
    "   - Use **k-fold cross-validation** for robust evaluation, especially with small datasets.  \n",
    "   - The dataset is split into $k$ subsets (folds). The model is trained $k$ times, using $k-1$ folds for training and 1 fold for validation each time.\n",
    "\n",
    "---\n",
    "\n",
    "## **<font color='purple'>6. Summary Table</font>**\n",
    "\n",
    "| **Set**         | **Purpose**                             | **Example**                  |\n",
    "|------------------|-----------------------------------------|------------------------------|\n",
    "| **Training Set** | Train the model to learn relationships. | 800 samples out of 1,000     |\n",
    "| **Validation Set** | Tune hyperparameters, detect overfitting. | 100 samples for validation   |\n",
    "| **Test Set**     | Final evaluation on unseen data.       | 100 samples for testing      |\n",
    "\n",
    "---\n",
    "\n",
    "# **<font color='darkorange'>Conclusion</font>**\n",
    "\n",
    "In this section:\n",
    "- We defined the **hypothesis** and the **hypothesis space** as the set of all possible models.  \n",
    "- We explained **inductive bias** and its importance in generalization.  \n",
    "- We introduced **Occam's Razor**, a principle that favors simpler models.    \n",
    "- We introduced the **training set**, **validation set**, and **test set**.  \n",
    "- We explained the purpose of each set in evaluating machine learning models.  \n",
    "- We highlighted the importance of using the validation set for **hyperparameter tuning** to avoid overfitting.  \n",
    "- Best practices like **cross-validation** were discussed for more robust evaluation.\n",
    "\n",
    "Understanding these concepts ensures the development of machine learning models that **generalize well** to unseen data, providing reliable and accurate predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QKq93gKeA_2q"
   },
   "source": [
    "# 🧠 Main Challenges of Machine Learning\n",
    "\n",
    "Machine Learning is powerful but comes with various challenges. Addressing these challenges with practical examples helps in building effective models.\n",
    "\n",
    "---\n",
    "\n",
    "## 1️⃣ Insufficient Quantity of Training Data\n",
    "\n",
    "A Machine Learning model requires a significant amount of training data to generalize well.  \n",
    "\n",
    "**Example:**  \n",
    "Imagine you’re training a face recognition system with only 50 images. The system may fail to recognize new faces due to insufficient diversity in the dataset.  \n",
    "\n",
    "**Solution:**  \n",
    "- Collect more diverse images.\n",
    "- Use data augmentation (e.g., rotate, crop, or flip images) to artificially increase the dataset size.\n",
    "\n",
    "---\n",
    "\n",
    "## 2️⃣ Nonrepresentative Training Data\n",
    "\n",
    "The training data must reflect the conditions under which the model will operate.  \n",
    "\n",
    "**Example:**  \n",
    "Suppose you’re training a weather prediction model using data from only one city. When applied to another city with different weather patterns, the predictions are inaccurate.  \n",
    "\n",
    "**Solution:**  \n",
    "- Use a dataset that includes data from multiple regions.\n",
    "- Check the dataset for potential biases during exploratory data analysis.\n",
    "\n",
    "---\n",
    "\n",
    "## 3️⃣ Poor-Quality Data\n",
    "\n",
    "Poor data quality, like missing values, outliers, or noise, hampers model performance.  \n",
    "\n",
    "**Example:**  \n",
    "A customer churn prediction model trained on data with inconsistent entries, like missing income values or outlier ages (e.g., 200 years), will yield unreliable results.  \n",
    "\n",
    "**Solution:**  \n",
    "- Handle missing values (e.g., replace with mean/median).\n",
    "- Remove outliers or cap extreme values.\n",
    "- Apply noise-reduction techniques.\n",
    "\n",
    "---\n",
    "\n",
    "## 4️⃣ Irrelevant Features\n",
    "\n",
    "Irrelevant or redundant features increase complexity without improving the model’s performance.  \n",
    "\n",
    "**Example:**  \n",
    "Predicting house prices with irrelevant features like the color of the house or the number of pets owned by the seller will confuse the model.  \n",
    "\n",
    "**Solution:**  \n",
    "- Perform **feature selection** using techniques like correlation analysis or mutual information.\n",
    "- Use dimensionality reduction techniques such as PCA.\n",
    "\n",
    "---\n",
    "\n",
    "## 5️⃣ Overfitting the Training Data\n",
    "\n",
    "The model performs exceptionally well on training data but poorly on unseen data.  \n",
    "\n",
    "**Example:**  \n",
    "A decision tree that memorizes every data point, including noise, may classify training samples perfectly but fail to generalize to test data.  \n",
    "\n",
    "**Solution:**  \n",
    "- Use regularization techniques like L1/L2 penalties.  \n",
    "- Prune decision trees to limit complexity.  \n",
    "- Perform k-fold cross-validation to evaluate generalization.\n",
    "\n",
    "---\n",
    "\n",
    "## 6️⃣ Underfitting the Training Data\n",
    "\n",
    "The model is too simple to capture the patterns in the data.  \n",
    "\n",
    "**Example:**  \n",
    "Fitting a linear regression model to predict house prices in a dataset where the relationship is clearly nonlinear will result in poor predictions.  \n",
    "\n",
    "**Solution:**  \n",
    "- Use a more complex model like polynomial regression.  \n",
    "- Ensure sufficient and relevant features are used.  \n",
    "- Train for more epochs if applicable.\n",
    "\n",
    "---\n",
    "\n",
    "## 7️⃣ Testing and Validating\n",
    "\n",
    "Improper testing or validation can lead to misleading results.  \n",
    "\n",
    "**Example:**  \n",
    "Using the same dataset for both training and testing will give an overly optimistic estimate of the model’s performance.  \n",
    "\n",
    "**Solution:**  \n",
    "- Split the dataset into training, validation, and test sets (e.g., 60/20/20 split).  \n",
    "- Use **k-fold cross-validation** for robust evaluation.\n",
    "\n",
    "---\n",
    "\n",
    "## 8️⃣ Hyperparameter Tuning and Model Selection\n",
    "\n",
    "Finding the best model and its optimal settings is challenging due to many hyperparameters.  \n",
    "\n",
    "**Example:**  \n",
    "Training a Random Forest model without tuning parameters like the number of trees or depth may result in suboptimal performance.  \n",
    "\n",
    "**Solution:**  \n",
    "- Use automated tuning methods like **Grid Search**, **Random Search**, or **Bayesian Optimization**.  \n",
    "- Compare multiple models (e.g., SVM, Random Forest, Neural Networks) on validation metrics to select the best one.\n",
    "\n",
    "---\n",
    "\n",
    "## 9️⃣ Data Mismatch\n",
    "\n",
    "Differences between training and production data (data drift) degrade performance.  \n",
    "\n",
    "**Example:**  \n",
    "A customer recommendation model trained on last year’s product preferences might fail because customer interests have changed.  \n",
    "\n",
    "**Solution:**  \n",
    "- Regularly retrain the model with fresh data.  \n",
    "- Use domain adaptation techniques to adjust the model for new conditions.\n",
    "\n",
    "By addressing these challenges thoughtfully and leveraging appropriate techniques, you can build more robust and effective Machine Learning systems.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QGLdiQOK5HUT"
   },
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 355,
     "status": "ok",
     "timestamp": 1735630372270,
     "user": {
      "displayName": "Sujoy Sarkar",
      "userId": "17276623725276932335"
     },
     "user_tz": -330
    },
    "id": "zoU-4oMMi8ir",
    "outputId": "46f05cd6-237b-4cff-b4f8-b09945028ef5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-04-27 23:30:11--  https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... failed: Temporary failure in name resolution.\n",
      "wget: unable to resolve host address ‘raw.githubusercontent.com’\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "executionInfo": {
     "elapsed": 2183,
     "status": "ok",
     "timestamp": 1735631586426,
     "user": {
      "displayName": "Sujoy Sarkar",
      "userId": "17276623725276932335"
     },
     "user_tz": -330
    },
    "id": "BPInOaHRiDZ7",
    "outputId": "e6c3d648-b42e-4747-d6af-33353b17dfff"
   },
   "outputs": [
    {
     "ename": "URLError",
     "evalue": "<urlopen error [Errno -3] Temporary failure in name resolution>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/usr/lib/python3.10/urllib/request.py:1348\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1348\u001b[0m     \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1349\u001b[0m \u001b[43m              \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTransfer-encoding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1350\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:1283\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1283\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:1329\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1328\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1329\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:1278\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1278\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:1038\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1038\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1041\u001b[0m \n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:976\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[0;32m--> 976\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:1448\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnect to a host on a given (SSL) port.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:942\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    941\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp.client.connect\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport)\n\u001b[0;32m--> 942\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;66;03m# Might fail in OSs that don't implement TCP_NODELAY\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/socket.py:824\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    823\u001b[0m err \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 824\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSOCK_STREAM\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    825\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[0;32m/usr/lib/python3.10/socket.py:955\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    954\u001b[0m addrlist \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 955\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_socket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    956\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "\u001b[0;31mgaierror\u001b[0m: [Errno -3] Temporary failure in name resolution",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpytorch/vision:v0.10.0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmobilenet_v2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Download an example image from the pytorch website\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/hub.py:638\u001b[0m, in \u001b[0;36mload\u001b[0;34m(repo_or_dir, model, source, trust_repo, force_reload, verbose, skip_validation, *args, **kwargs)\u001b[0m\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnknown source: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. Allowed values: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgithub\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m | \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    635\u001b[0m     )\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgithub\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 638\u001b[0m     repo_or_dir \u001b[38;5;241m=\u001b[39m \u001b[43m_get_cache_or_reload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_or_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    640\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_reload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrust_repo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    642\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mload\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskip_validation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_validation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    647\u001b[0m model \u001b[38;5;241m=\u001b[39m _load_local(repo_or_dir, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/hub.py:258\u001b[0m, in \u001b[0;36m_get_cache_or_reload\u001b[0;34m(github, force_reload, trust_repo, calling_fn, verbose, skip_validation)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;66;03m# Validate the tag/branch is from the original repo instead of a forked repo\u001b[39;00m\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_validation:\n\u001b[0;32m--> 258\u001b[0m         \u001b[43m_validate_not_a_forked_repo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_owner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepo_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m     cached_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(hub_dir, normalized_br \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    261\u001b[0m     _remove_if_exists(cached_file)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/hub.py:203\u001b[0m, in \u001b[0;36m_validate_not_a_forked_repo\u001b[0;34m(repo_owner, repo_name, ref)\u001b[0m\n\u001b[1;32m    201\u001b[0m page \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    202\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m?per_page=100&page=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 203\u001b[0m response \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(\u001b[43m_read_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    204\u001b[0m \u001b[38;5;66;03m# Empty response means no more data to process\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m response:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/hub.py:185\u001b[0m, in \u001b[0;36m_read_url\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_url\u001b[39m(url):\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m r:\n\u001b[1;32m    186\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m r\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39mdecode(r\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget_content_charset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m/usr/lib/python3.10/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/urllib/request.py:519\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    516\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[1;32m    518\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[0;32m--> 519\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[1;32m    522\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/usr/lib/python3.10/urllib/request.py:536\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m    535\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[0;32m--> 536\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[1;32m    537\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_open\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/lib/python3.10/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/lib/python3.10/urllib/request.py:1391\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[0;32m-> 1391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/urllib/request.py:1351\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m         h\u001b[38;5;241m.\u001b[39mrequest(req\u001b[38;5;241m.\u001b[39mget_method(), req\u001b[38;5;241m.\u001b[39mselector, req\u001b[38;5;241m.\u001b[39mdata, headers,\n\u001b[1;32m   1349\u001b[0m                   encode_chunked\u001b[38;5;241m=\u001b[39mreq\u001b[38;5;241m.\u001b[39mhas_header(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransfer-encoding\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m   1350\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[0;32m-> 1351\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[1;32m   1352\u001b[0m     r \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m   1353\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[0;31mURLError\u001b[0m: <urlopen error [Errno -3] Temporary failure in name resolution>"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# Download an example image from the pytorch website\n",
    "import urllib\n",
    "url, filename = (\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Cat03.jpg/640px-Cat03.jpg\", \"cat.jpg\")\n",
    "try: urllib.URLopener().retrieve(url, filename)\n",
    "except: urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "# sample execution (requires torchvision)\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "input_image = Image.open(filename)\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)\n",
    "\n",
    "# The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
    "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "\n",
    "\n",
    "# Read the categories\n",
    "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
    "    categories = [s.strip() for s in f.readlines()]\n",
    "\n",
    "# Show top categories per image\n",
    "top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "for i in range(top5_prob.size(0)):\n",
    "    print(categories[top5_catid[i]], top5_prob[i].item())\n",
    "\n",
    "# Step 7: Display the Image\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(input_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 417,
     "status": "ok",
     "timestamp": 1735630096132,
     "user": {
      "displayName": "Sujoy Sarkar",
      "userId": "17276623725276932335"
     },
     "user_tz": -330
    },
    "id": "HTtMx-EDivw9"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AWTRSFB6jHrX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
